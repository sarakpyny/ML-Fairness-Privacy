{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce422ca9",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bccd7",
   "metadata": {},
   "source": [
    "### For COMPASS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff8d34d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPAS preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "\n",
    "# Keep standard COMPAS filtering (as in literature)\n",
    "df = df[\n",
    "    (df['days_b_screening_arrest'] <= 30) &\n",
    "    (df['days_b_screening_arrest'] >= -30) &\n",
    "    (df['is_recid'] != -1) &\n",
    "    (df['c_charge_degree'] != 'O') &\n",
    "    (df['score_text'] != 'N/A')\n",
    "]\n",
    "\n",
    "# Label: recidivism\n",
    "df[\"label\"] = df[\"two_year_recid\"]\n",
    "\n",
    "# Sensitive attribute: race (Black vs Non-Black)\n",
    "df[\"race\"] = (df[\"race\"] == \"African-American\").astype(int)\n",
    "\n",
    "# Select features (standard choice)\n",
    "features = [\n",
    "    'age',\n",
    "    'priors_count',\n",
    "    'juv_fel_count',\n",
    "    'juv_misd_count',\n",
    "    'juv_other_count',\n",
    "    'c_charge_degree'\n",
    "]\n",
    "\n",
    "df = df[features + [\"label\", \"race\"]]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "num_cols = [\n",
    "    'age', 'priors_count',\n",
    "    'juv_fel_count', 'juv_misd_count', 'juv_other_count'\n",
    "]\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Train / Val / Test split\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "train.to_csv(\"compas_train.csv\", index=False)\n",
    "val.to_csv(\"compas_val.csv\", index=False)\n",
    "test.to_csv(\"compas_test.csv\", index=False)\n",
    "\n",
    "print(\"COMPAS preprocessing done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e33f1",
   "metadata": {},
   "source": [
    "### Train RNF for COMPASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09dd89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Training RNF on COMPAS...\n",
      "Epoch 1: loss=0.6582, acc=60.74\n",
      "Epoch 2: loss=0.6141, acc=67.01\n",
      "Epoch 3: loss=0.6128, acc=67.29\n",
      "Epoch 4: loss=0.6068, acc=67.85\n",
      "Epoch 5: loss=0.6042, acc=68.59\n",
      "Epoch 6: loss=0.6059, acc=67.87\n",
      "Epoch 7: loss=0.6037, acc=68.12\n",
      "Epoch 8: loss=0.6020, acc=68.31\n",
      "Epoch 9: loss=0.6032, acc=68.10\n",
      "Epoch 10: loss=0.2768, acc=63.43\n",
      "Epoch 11: loss=0.2731, acc=65.46\n",
      "Epoch 12: loss=0.2724, acc=65.88\n",
      "Epoch 13: loss=0.2714, acc=66.02\n",
      "\n",
      "Final Results (RNF)\n",
      "Accuracy: 0.6457883369330454\n",
      "DP: 0.1677908740809896\n",
      "EO: 0.22042601749714721\n",
      "Positive rate: 0.22354211663066956\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "from mlp import Net, FC\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS_FIRST = 9\n",
    "EPOCHS_SECOND = 4     # RNF head training only\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 50\n",
    "\n",
    "ALPHA = 0.1      # RNF regularization\n",
    "CE_WEIGHT = 0.4       # anti-collapse supervision\n",
    "TEMPERATURE = 5.0\n",
    "\n",
    "# Dataset\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, s):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.s = s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], int(self.y[idx]), int(self.s[idx])\n",
    "\n",
    "\n",
    "def load_compas(batch_size):\n",
    "    def load(path):\n",
    "        df = pd.read_csv(path)\n",
    "        X = df.drop(columns=[\"label\", \"race\"]).astype(\"float32\").values\n",
    "        y = df[\"label\"].astype(int).values\n",
    "        s = df[\"race\"].astype(int).values\n",
    "        return Dataset(X, y, s)\n",
    "\n",
    "    train = data.DataLoader(load(\"compas_train.csv\"), batch_size, shuffle=True)\n",
    "    val = data.DataLoader(load(\"compas_val.csv\"), batch_size)\n",
    "    test = data.DataLoader(load(\"compas_test.csv\"), batch_size)\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "# RNF Feature Neutralization\n",
    "def feature_neutralization(r, p, y, s):\n",
    "    groups = {(0, 0): [], (0, 1): [], (1, 0): [], (1, 1): []}\n",
    "    for i in range(len(y)):\n",
    "        groups[(int(y[i]), int(s[i]))].append((r[i], p[i]))\n",
    "\n",
    "    def sample(y, s):\n",
    "        alt = groups[(y, 1-s)]\n",
    "        return random.choice(alt if len(alt) > 0 else groups[(y, s)])\n",
    "\n",
    "    reps = []\n",
    "    for w in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        r_new = torch.zeros_like(r)\n",
    "        for i in range(len(y)):\n",
    "            r_alt, _ = sample(int(y[i]), int(s[i]))\n",
    "            r_new[i] = w * r[i] + (1 - w) * r_alt\n",
    "        reps.append(r_new.to(device))\n",
    "\n",
    "    p_new = torch.zeros_like(p)\n",
    "    for i in range(len(y)):\n",
    "        _, p_alt = sample(int(y[i]), int(s[i]))\n",
    "        p_new[i] = 0.5 * p[i] + 0.5 * p_alt\n",
    "\n",
    "    return reps, p_new.to(device)\n",
    "\n",
    "\n",
    "# Training\n",
    "def train_epoch(model, head, loader, ce_loss, kd_loss,\n",
    "                opt_enc, opt_head, epoch):\n",
    "\n",
    "    model.train()\n",
    "    head.train()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for x, y, s in loader:\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "        s = s.long().to(device)\n",
    "\n",
    "        logits, r = model(x)\n",
    "\n",
    "        # Stage 1: standard supervised training\n",
    "        if epoch < EPOCHS_FIRST:\n",
    "            logp = F.log_softmax(logits, dim=1)\n",
    "            loss = ce_loss(logp, y)\n",
    "\n",
    "            opt_enc.zero_grad()\n",
    "            loss.backward()\n",
    "            opt_enc.step()\n",
    "\n",
    "            preds = logp.argmax(dim=1)\n",
    "\n",
    "        # Stage 2: RNF (encoder frozen)\n",
    "        else:\n",
    "            for p_enc in model.parameters():\n",
    "                p_enc.requires_grad = False\n",
    "\n",
    "            with torch.no_grad():\n",
    "                p = softmax(logits / TEMPERATURE)\n",
    "\n",
    "            reps, p_neu = feature_neutralization(r, p, y, s)\n",
    "\n",
    "            pred_neu = softmax(head(reps[0]))\n",
    "            kd = kd_loss(pred_neu, p_neu)\n",
    "\n",
    "            ce = ce_loss(F.log_softmax(head(r), dim=1), y)\n",
    "\n",
    "            reg = 0\n",
    "            for rep in reps[1:]:\n",
    "                reg += torch.abs(softmax(head(rep)) - pred_neu).mean()\n",
    "\n",
    "            loss = kd + CE_WEIGHT * ce + ALPHA * reg\n",
    "\n",
    "            opt_head.zero_grad()\n",
    "            loss.backward()\n",
    "            opt_head.step()\n",
    "\n",
    "            preds = head(r).argmax(dim=1)\n",
    "\n",
    "        y_true.extend(y.cpu().tolist())\n",
    "        y_pred.extend(preds.cpu().tolist())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    return total_loss / len(loader), acc\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, head, loader):\n",
    "    model.eval()\n",
    "    head.eval()\n",
    "\n",
    "    y_true, y_pred, s_all = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, s in loader:\n",
    "            x = x.float().to(device)\n",
    "            _, r = model(x)\n",
    "            pred = head(r).argmax(dim=1)\n",
    "\n",
    "            y_true.extend(y.tolist())\n",
    "            y_pred.extend(pred.cpu().tolist())\n",
    "            s_all.extend(s.tolist())\n",
    "\n",
    "    return y_true, y_pred, s_all\n",
    "\n",
    "\n",
    "# Main\n",
    "train_iter, val_iter, test_iter = load_compas(BATCH_SIZE)\n",
    "INPUT_DIM = next(iter(train_iter))[0].shape[1]\n",
    "\n",
    "model = Net(INPUT_DIM, HIDDEN_DIM, 2).to(device)\n",
    "head = FC(HIDDEN_DIM, HIDDEN_DIM, 2).to(device)\n",
    "\n",
    "opt_enc = optim.Adam(model.parameters(), lr=1e-3)\n",
    "opt_head = optim.Adam(head.parameters(), lr=1e-3)\n",
    "\n",
    "ce_loss = nn.NLLLoss()\n",
    "kd_loss = nn.MSELoss()\n",
    "\n",
    "print(\"\\nTraining RNF on COMPAS...\")\n",
    "for epoch in range(EPOCHS_FIRST + EPOCHS_SECOND):\n",
    "    loss, acc = train_epoch(\n",
    "        model, head, train_iter,\n",
    "        ce_loss, kd_loss,\n",
    "        opt_enc, opt_head,\n",
    "        epoch\n",
    "    )\n",
    "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, acc={acc*100:.2f}\")\n",
    "\n",
    "# Final evaluation\n",
    "y_true, y_pred, s = evaluate(model, head, test_iter)\n",
    "\n",
    "print(\"\\nFinal Results (RNF)\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "print(\"DP:\", demographic_parity_difference(\n",
    "    y_true, y_pred, sensitive_features=s))\n",
    "print(\"EO:\", equalized_odds_difference(y_true, y_pred, sensitive_features=s))\n",
    "print(\"Positive rate:\", np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367238b",
   "metadata": {},
   "source": [
    "### Baseline model (Stage 1 of RNF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b100695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Training baseline MLP...\n",
      "Epoch 1: acc=61.00\n",
      "Epoch 2: acc=67.69\n",
      "Epoch 3: acc=67.50\n",
      "Epoch 4: acc=67.78\n",
      "Epoch 5: acc=68.06\n",
      "Epoch 6: acc=68.19\n",
      "Epoch 7: acc=67.59\n",
      "Epoch 8: acc=68.06\n",
      "Epoch 9: acc=68.50\n",
      "\n",
      "Final Results (Baseline)\n",
      "Accuracy: 0.6760259179265659\n",
      "DP: 0.23107947251721322\n",
      "EO: 0.2453879802206162\n",
      "Positive rate: 0.4200863930885529\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "from mlp import Net\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    " \n",
    "# Hyperparameters (match RNF stage 1)\n",
    "EPOCHS = 9\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 50\n",
    "LR = 1e-3\n",
    "\n",
    "# Dataset\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, s):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.s = s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], int(self.y[idx]), int(self.s[idx])\n",
    "\n",
    "\n",
    "def load_compas(batch_size):\n",
    "    def load(path):\n",
    "        df = pd.read_csv(path)\n",
    "        X = df.drop(columns=[\"label\", \"race\"]).astype(\"float32\").values\n",
    "        y = df[\"label\"].astype(int).values\n",
    "        s = df[\"race\"].astype(int).values\n",
    "        return Dataset(X, y, s)\n",
    "\n",
    "    train = data.DataLoader(load(\"compas_train.csv\"), batch_size, shuffle=True)\n",
    "    test = data.DataLoader(load(\"compas_test.csv\"), batch_size)\n",
    "    return train, test\n",
    "\n",
    "\n",
    " \n",
    "# Training\n",
    "def train_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for x, y, _ in loader:\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "\n",
    "        logits, _ = model(x)\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        loss = loss_fn(logp, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true.extend(y.cpu().tolist())\n",
    "        y_pred.extend(logp.argmax(dim=1).cpu().tolist())\n",
    "\n",
    "    return np.mean(np.array(y_true) == np.array(y_pred))\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred, s_all = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, s in loader:\n",
    "            x = x.float().to(device)\n",
    "            logits, _ = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "\n",
    "            y_true.extend(y.tolist())\n",
    "            y_pred.extend(pred.cpu().tolist())\n",
    "            s_all.extend(s.tolist())\n",
    "\n",
    "    return y_true, y_pred, s_all\n",
    "\n",
    "\n",
    "# Main\n",
    "train_iter, test_iter = load_compas(BATCH_SIZE)\n",
    "INPUT_DIM = next(iter(train_iter))[0].shape[1]\n",
    "\n",
    "model = Net(INPUT_DIM, HIDDEN_DIM, 2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "print(\"\\nTraining baseline MLP...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    acc = train_epoch(model, train_iter, optimizer, loss_fn)\n",
    "    print(f\"Epoch {epoch+1}: acc={acc*100:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "y_true, y_pred, s = evaluate(model, test_iter)\n",
    "\n",
    "print(\"\\nFinal Results (Baseline)\")\n",
    "print(\"Accuracy:\", np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "print(\"DP:\", demographic_parity_difference(\n",
    "    y_true, y_pred, sensitive_features=s))\n",
    "print(\"EO:\", equalized_odds_difference(y_true, y_pred, sensitive_features=s))\n",
    "print(\"Positive rate:\", np.mean(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
